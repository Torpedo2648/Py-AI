{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 垃圾短信拦截器\n",
    "\n",
    "使用[垃圾短信数据集](https://archive-beta.ics.uci.edu/ml/datasets/sentiment+labelled+sentences)\n",
    "- 通过spacy获取短信向量表达\n",
    "- 建立多层感知机进行分类\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/jovyan/.config/pip/pip.conf\n",
      "Writing to /home/jovyan/.config/pip/pip.conf\n",
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (59.1.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (6.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip config set global.index-url http://pypi.douban.com/simple\n",
    "! pip config set install.trusted-host pypi.douban.com\n",
    "\n",
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 13:13:58.206534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 13:13:58.207253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-09 13:13:58.207607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "! spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先下载数据集并解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "ham\tU dun say so early hor... U c already then say...\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\n",
      "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "! [ -e smsspamcollection.zip ] || \\\n",
    "    wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "! [ -e \"SMSSpamCollection\" ] || \\\n",
    "    unzip smsspamcollection.zip -d .\n",
    "! head SMSSpamCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每行数据的格式为：\n",
    "```\n",
    "<label>\\t<sms>\n",
    "```\n",
    "使用`pandas`读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                sms\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"sms\"], header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机打乱数据集并获取一些基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "data = df.sample(frac=1)  # sample 100% => shuffle\n",
    "n = 2  # number of classes\n",
    "m = len(data)  # number of samples\n",
    "m_train = int(m * 0.8)  # number of training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载spacy模型备用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取训练集和测试集（需使用上面的`nlp`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>index</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..k:)how about your training process?</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.22786477, -0.48382202, 0.18847908, -0.31621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>ham</td>\n",
       "      <td>I told that am coming on wednesday.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.055274762, 0.39225176, 0.37901777, -0.3056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>spam</td>\n",
       "      <td>Sunshine Quiz Wkly Q! Win a top Sony DVD playe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.35940382, 0.03139996, -0.012604602, -0.2474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>spam</td>\n",
       "      <td>TheMob&gt;Hit the link to get a premium Pink Pant...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.25135776, 0.06056308, -0.028496165, 0.05041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Do u konw waht is rael FRIENDSHIP Im gving yuo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.15112671, -0.15580621, 0.008872468, -0.2764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ü dun need to pick ur gf?</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.15914485, -0.03889931, 0.69562125, -0.15143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>ham</td>\n",
       "      <td>on hen night. Going with a swing</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.27193192, -0.05489895, 0.67185766, -0.0789...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dunno lei... I thk mum lazy to go out... I nev...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010996377, -0.02518764, 0.13231944, -0.2391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wewa is 130. Iriver 255. All 128 mb.</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.34038374, 0.043166257, -0.09735346, -0.915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>ham</td>\n",
       "      <td>I love you both too :-)</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0132942395, 0.5451732, -0.3229695, -0.7140...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                sms  index  \\\n",
       "3084   ham             K..k:)how about your training process?      0   \n",
       "4164   ham                I told that am coming on wednesday.      0   \n",
       "1691  spam  Sunshine Quiz Wkly Q! Win a top Sony DVD playe...      1   \n",
       "5098  spam  TheMob>Hit the link to get a premium Pink Pant...      1   \n",
       "1542   ham  Do u konw waht is rael FRIENDSHIP Im gving yuo...      0   \n",
       "...    ...                                                ...    ...   \n",
       "1174   ham                          Ü dun need to pick ur gf?      0   \n",
       "1106   ham                   on hen night. Going with a swing      0   \n",
       "2011   ham  Dunno lei... I thk mum lazy to go out... I nev...      0   \n",
       "4678   ham               Wewa is 130. Iriver 255. All 128 mb.      0   \n",
       "3552   ham                            I love you both too :-)      0   \n",
       "\n",
       "                                                 vector  \n",
       "3084  [0.22786477, -0.48382202, 0.18847908, -0.31621...  \n",
       "4164  [-0.055274762, 0.39225176, 0.37901777, -0.3056...  \n",
       "1691  [0.35940382, 0.03139996, -0.012604602, -0.2474...  \n",
       "5098  [0.25135776, 0.06056308, -0.028496165, 0.05041...  \n",
       "1542  [0.15112671, -0.15580621, 0.008872468, -0.2764...  \n",
       "...                                                 ...  \n",
       "1174  [0.15914485, -0.03889931, 0.69562125, -0.15143...  \n",
       "1106  [-0.27193192, -0.05489895, 0.67185766, -0.0789...  \n",
       "2011  [0.010996377, -0.02518764, 0.13231944, -0.2391...  \n",
       "4678  [-0.34038374, 0.043166257, -0.09735346, -0.915...  \n",
       "3552  [-0.0132942395, 0.5451732, -0.3229695, -0.7140...  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to prepare train_data, train_targes, test_data, test_targets\n",
    "# map labels to indexes, and sms to vectors\n",
    "data[\"index\"] = data[\"label\"].map(lambda x: 1 if x == \"spam\" else 0)\n",
    "data[\"vector\"] = data[\"sms\"].map(lambda x: nlp(x).vector)\n",
    "\n",
    "# keep the first `m_train` as train data and the rest for test\n",
    "train_data = data[:m_train][\"vector\"].to_numpy()\n",
    "train_targets = data[:m_train][\"index\"].to_numpy()\n",
    "test_data = data[m_train:][\"vector\"].to_numpy()\n",
    "test_targets = data[m_train:][\"index\"].to_numpy()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train spam: 598/4457\n",
      "test spam: 149/1115\n"
     ]
    }
   ],
   "source": [
    "print(f\"train spam: {train_targets.sum()}/{len(train_targets)}\")\n",
    "print(f\"test spam: {test_targets.sum()}/{len(test_targets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转为pytorch的`DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "batch_size = 8\n",
    "# make dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(list(zip(train_data, train_targets)), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(list(zip(test_data, test_targets)), batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "# Your code here to define a MLP or whatever network you want\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(96, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 2)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数和工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimizer\n",
    "from torch import optim\n",
    "\n",
    "# tune only the MLP's parameter\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# setup the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def train(train_loader, net, optimizer, loss_fn):\n",
    "    # your code here to implement a training epoch\n",
    "    # 0. set model to train mode\n",
    "    net.train()\n",
    "    # 1. initialize a correct sample counter and a loss collection\n",
    "    correct = 0\n",
    "    loss_list = []\n",
    "    # 2. traverse for each sample in `train_loader`\n",
    "    for inputs, labels in train_loader:\n",
    "        # 0. move inputs and labels to device\n",
    "        inputs.to(device)\n",
    "        labels.to(device)\n",
    "        # 1. zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # 2. get output with forward pass\n",
    "        outputs = net(inputs)\n",
    "        # 3. get loss value with loss_fn\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # 4. backward and take an optimize step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 5. collect the correct sample and the loss\n",
    "        pred = outputs.argmax(1)\n",
    "        correct += (pred == labels).detach().cpu().numpy()\n",
    "        loss_list.append(loss.detach().cpu().numpy())\n",
    "    # 3. calculate the accuracy and the average loss\n",
    "    accuracy = correct / len(train_loader)\n",
    "    avg_loss = sum(loss_list) / len(loss_list)\n",
    "    # 4. return the accuracy and the loss\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "def test(test_loader, net, loss_fn):\n",
    "    # your code here to implement a testing epoch\n",
    "    # 0. set model to evaluation mode\n",
    "    net.eval()\n",
    "    # 1. initialize a correct sample counter and a loss collection\n",
    "    correct = 0\n",
    "    loss_list = []\n",
    "    # 2. turn off gradient collection\n",
    "    with torch.no_grad():\n",
    "        # 3. traverse for each sample in `test_loader`\n",
    "        for inputs, labels in test_loader:\n",
    "            # 0. move inputs and labels to device\n",
    "            inputs.to(device)\n",
    "            labels.to(device)\n",
    "            # 1. get output with forward pass\n",
    "            outputs = net(inputs)\n",
    "            # 2. get loss value with loss_fn\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # 3. collect the correct sample and the loss\n",
    "            pred = outputs.argmax(1)\n",
    "            correct += (pred == labels).detach().cpu().numpy()\n",
    "            loss_list.append(loss.detach().cpu().numpy())\n",
    "    # 4. calculate the accuracy and the average loss\n",
    "    accuracy = correct / len(train_loader)\n",
    "    avg_loss = sum(loss_list) / len(loss_list)\n",
    "    # 5. return the accuracy and the loss \n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_list = []\n",
    "loss_train_list = []\n",
    "accuracy_test_list = []\n",
    "loss_test_list = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    # your code here to train and test the model\n",
    "    accuracy_train, loss_train = train(train_loader, net, optimizer, loss_fn)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    loss_train_list.append(loss_train)\n",
    "    \n",
    "    accuracy_test, loss_test = test(train_loader, net, loss_fn)\n",
    "    accuracy_test_list.append(accuracy_test)\n",
    "    loss_test_list.append(loss_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc = [array([0.98028674, 0.97849462, 0.97132616, 0.96594982, 0.96236559,\n",
      "       0.96774194, 0.98207885, 0.97311828]), array([0.98387097, 0.97849462, 0.98387097, 0.97311828, 0.98387097,\n",
      "       0.96774194, 0.98207885, 0.97491039]), array([0.97849462, 0.98028674, 0.98387097, 0.97849462, 0.98207885,\n",
      "       0.97849462, 0.96774194, 0.98924731]), array([0.98566308, 0.98387097, 0.98387097, 0.98207885, 0.97849462,\n",
      "       0.98387097, 0.9874552 , 0.99103943]), array([0.99103943, 0.9874552 , 0.98566308, 0.97491039, 0.9874552 ,\n",
      "       0.99462366, 0.9874552 , 0.99103943]), array([0.9874552 , 0.99641577, 0.99283154, 0.9874552 , 0.98924731,\n",
      "       0.98566308, 0.99103943, 0.99462366]), array([0.99103943, 0.99283154, 0.98924731, 0.9874552 , 0.99283154,\n",
      "       0.98924731, 0.98566308, 0.98387097]), array([0.99283154, 0.99641577, 0.98924731, 0.99103943, 0.99641577,\n",
      "       0.99462366, 0.98924731, 0.99283154]), array([1.        , 1.        , 0.98387097, 0.99641577, 0.99462366,\n",
      "       0.99103943, 0.99103943, 0.99462366]), array([0.99283154, 0.99103943, 0.99283154, 0.99820789, 0.99462366,\n",
      "       0.99283154, 0.99103943, 0.99641577]), array([0.99641577, 0.99283154, 1.        , 0.99283154, 0.99820789,\n",
      "       0.99641577, 0.99820789, 0.99820789]), array([0.99103943, 0.99820789, 0.99283154, 0.99641577, 0.99641577,\n",
      "       0.99641577, 0.99820789, 0.99283154]), array([0.99462366, 0.99641577, 0.99283154, 1.        , 1.        ,\n",
      "       0.99462366, 0.99820789, 0.99641577]), array([0.99462366, 0.99641577, 0.99820789, 0.99641577, 0.99820789,\n",
      "       0.99820789, 1.        , 0.99641577]), array([0.99820789, 0.99820789, 1.        , 0.99820789, 1.        ,\n",
      "       0.99641577, 1.        , 1.        ]), array([1.        , 0.99820789, 1.        , 1.        , 1.        ,\n",
      "       0.99820789, 1.        , 1.        ]), array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1.        , 1.        , 1.        , 0.99820789, 1.        ,\n",
      "       0.99641577, 0.99820789, 1.        ]), array([1.        , 1.        , 0.99820789, 1.        , 0.99820789,\n",
      "       1.        , 1.        , 1.        ]), array([1.        , 1.        , 0.99641577, 1.        , 1.        ,\n",
      "       0.99820789, 0.99820789, 1.        ])], test_acc = [array([0.97311828, 0.97670251, 0.97670251, 0.98387097, 0.97132616,\n",
      "       0.97849462, 0.97849462, 0.98566308]), array([0.97849462, 0.98387097, 0.9874552 , 0.98387097, 0.98387097,\n",
      "       0.98207885, 0.98028674, 0.97670251]), array([0.99103943, 0.99283154, 0.98566308, 0.97311828, 0.98207885,\n",
      "       0.98387097, 0.98028674, 0.98387097]), array([0.99283154, 0.98387097, 0.99283154, 0.97670251, 0.99820789,\n",
      "       0.98924731, 0.99462366, 0.98566308]), array([0.98028674, 0.9874552 , 0.99462366, 0.98028674, 0.98387097,\n",
      "       0.99103943, 0.99462366, 0.99103943]), array([0.97849462, 0.99283154, 0.99283154, 0.9874552 , 0.98924731,\n",
      "       0.99283154, 0.99103943, 0.99103943]), array([0.99462366, 0.99462366, 0.99462366, 0.99283154, 0.98924731,\n",
      "       0.99103943, 0.99103943, 0.99103943]), array([0.99283154, 0.99462366, 0.99462366, 0.99641577, 0.99462366,\n",
      "       0.99641577, 0.99283154, 0.99462366]), array([0.99641577, 0.99641577, 0.99103943, 0.99283154, 0.99641577,\n",
      "       0.99641577, 0.99641577, 0.99462366]), array([0.99820789, 0.99462366, 0.99283154, 1.        , 0.99641577,\n",
      "       0.99820789, 0.99283154, 0.99641577]), array([0.99641577, 0.99820789, 0.99641577, 0.99820789, 1.        ,\n",
      "       0.99462366, 0.99462366, 0.99820789]), array([0.99462366, 0.99820789, 0.99641577, 0.99283154, 0.99462366,\n",
      "       0.99820789, 1.        , 0.99820789]), array([0.99820789, 1.        , 1.        , 1.        , 0.99820789,\n",
      "       0.99462366, 1.        , 1.        ]), array([1.        , 0.99820789, 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99820789, 1.        ]), array([1.        , 1.        , 1.        , 1.        , 0.99820789,\n",
      "       1.        , 1.        , 1.        ]), array([1.        , 1.        , 1.        , 1.        , 0.99820789,\n",
      "       1.        , 0.99820789, 0.99820789]), array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99820789, 1.        ]), array([1.        , 0.99641577, 0.99283154, 0.99641577, 0.99641577,\n",
      "       1.        , 0.99820789, 1.        ]), array([1., 1., 1., 1., 1., 1., 1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_acc = {accuracy_train_list}, test_acc = {accuracy_test_list}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "568d99031516cb91b124139a50c43e0e628ee43803acee1edec6cbd47ca74668"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
